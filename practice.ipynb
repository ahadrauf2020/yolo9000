{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 129998 images in 200 classes\n",
      "{0: 'n01443537', 1: 'n01629819', 2: 'n01641577', 3: 'n01644900', 4: 'n01698640', 5: 'n01742172', 6: 'n01768244', 7: 'n01770393', 8: 'n01774384', 9: 'n01774750', 10: 'n01784675', 11: 'n01855672', 12: 'n01882714', 13: 'n01910747', 14: 'n01917289', 15: 'n01944390', 16: 'n01945685', 17: 'n01950731', 18: 'n01983481', 19: 'n01984695', 20: 'n02002724', 21: 'n02056570', 22: 'n02058221', 23: 'n02074367', 24: 'n02085620', 25: 'n02094433', 26: 'n02099601', 27: 'n02099712', 28: 'n02106662', 29: 'n02113799', 30: 'n02123045', 31: 'n02123394', 32: 'n02124075', 33: 'n02125311', 34: 'n02129165', 35: 'n02132136', 36: 'n02165456', 37: 'n02190166', 38: 'n02206856', 39: 'n02226429', 40: 'n02231487', 41: 'n02233338', 42: 'n02236044', 43: 'n02268443', 44: 'n02279972', 45: 'n02281406', 46: 'n02321529', 47: 'n02364673', 48: 'n02395406', 49: 'n02403003', 50: 'n02410509', 51: 'n02415577', 52: 'n02423022', 53: 'n02437312', 54: 'n02480495', 55: 'n02481823', 56: 'n02486410', 57: 'n02504458', 58: 'n02509815', 59: 'n02666196', 60: 'n02669723', 61: 'n02699494', 62: 'n02730930', 63: 'n02769748', 64: 'n02788148', 65: 'n02791270', 66: 'n02793495', 67: 'n02795169', 68: 'n02802426', 69: 'n02808440', 70: 'n02814533', 71: 'n02814860', 72: 'n02815834', 73: 'n02823428', 74: 'n02837789', 75: 'n02841315', 76: 'n02843684', 77: 'n02883205', 78: 'n02892201', 79: 'n02906734', 80: 'n02909870', 81: 'n02917067', 82: 'n02927161', 83: 'n02948072', 84: 'n02950826', 85: 'n02963159', 86: 'n02977058', 87: 'n02988304', 88: 'n02999410', 89: 'n03014705', 90: 'n03026506', 91: 'n03042490', 92: 'n03085013', 93: 'n03089624', 94: 'n03100240', 95: 'n03126707', 96: 'n03160309', 97: 'n03179701', 98: 'n03201208', 99: 'n03250847', 100: 'n03255030', 101: 'n03355925', 102: 'n03388043', 103: 'n03393912', 104: 'n03400231', 105: 'n03404251', 106: 'n03424325', 107: 'n03444034', 108: 'n03447447', 109: 'n03544143', 110: 'n03584254', 111: 'n03599486', 112: 'n03617480', 113: 'n03637318', 114: 'n03649909', 115: 'n03662601', 116: 'n03670208', 117: 'n03706229', 118: 'n03733131', 119: 'n03763968', 120: 'n03770439', 121: 'n03796401', 122: 'n03804744', 123: 'n03814639', 124: 'n03837869', 125: 'n03838899', 126: 'n03854065', 127: 'n03891332', 128: 'n03902125', 129: 'n03930313', 130: 'n03937543', 131: 'n03970156', 132: 'n03976657', 133: 'n03977966', 134: 'n03980874', 135: 'n03983396', 136: 'n03992509', 137: 'n04008634', 138: 'n04023962', 139: 'n04067472', 140: 'n04070727', 141: 'n04074963', 142: 'n04099969', 143: 'n04118538', 144: 'n04133789', 145: 'n04146614', 146: 'n04149813', 147: 'n04179913', 148: 'n04251144', 149: 'n04254777', 150: 'n04259630', 151: 'n04265275', 152: 'n04275548', 153: 'n04285008', 154: 'n04311004', 155: 'n04328186', 156: 'n04356056', 157: 'n04366367', 158: 'n04371430', 159: 'n04376876', 160: 'n04398044', 161: 'n04399382', 162: 'n04417672', 163: 'n04456115', 164: 'n04465501', 165: 'n04486054', 166: 'n04487081', 167: 'n04501370', 168: 'n04507155', 169: 'n04532106', 170: 'n04532670', 171: 'n04540053', 172: 'n04560804', 173: 'n04562935', 174: 'n04596742', 175: 'n04597913', 176: 'n06596364', 177: 'n07579787', 178: 'n07583066', 179: 'n07614500', 180: 'n07615774', 181: 'n07695742', 182: 'n07711569', 183: 'n07715103', 184: 'n07720875', 185: 'n07734744', 186: 'n07747607', 187: 'n07749582', 188: 'n07753592', 189: 'n07768694', 190: 'n07871810', 191: 'n07873807', 192: 'n07875152', 193: 'n07920052', 194: 'n09193705', 195: 'n09246464', 196: 'n09256479', 197: 'n09332890', 198: 'n09428293', 199: 'n12267677'}\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "\n",
    "data_dir = pathlib.Path('./data/tiny-imagenet-200')\n",
    "image_count = len(list(data_dir.glob('**/*.JPEG')))\n",
    "CLASS_NAMES = np.array([item.name for item in (data_dir / 'train').glob('*')])\n",
    "num_classes = len(CLASS_NAMES)\n",
    "print('Discovered {} images in {} classes'.format(image_count, num_classes))\n",
    "\n",
    "# Create the training data generator\n",
    "batch_size = 32\n",
    "im_height = 64\n",
    "im_width = 64\n",
    "num_epochs = 1\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "])\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=data_dir / 'train', transform=data_transforms),\n",
    "    'valid': datasets.ImageFolder(root=data_dir / 'val', transform=data_transforms),\n",
    "    'test': datasets.ImageFolder(root=data_dir / 'test', transform=data_transforms)\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_set = torchvision.datasets.ImageFolder(data_dir / 'train', data_transforms)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "#                                            shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Set train and valid directory paths\n",
    "# train_directory = os.path.join(dataset, 'train')\n",
    "# valid_directory = os.path.join(dataset, 'valid')\n",
    "# test_directory = os.path.join(dataset, 'test')\n",
    "\n",
    "# # Batch size\n",
    "# bs = 32\n",
    "\n",
    "# # Number of classes\n",
    "# num_classes = len(os.listdir(valid_directory))-1  #10#2#257\n",
    "# print(num_classes)\n",
    "\n",
    "# # Load Data from folders\n",
    "# data = {\n",
    "#     'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "#     'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n",
    "#     'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "# }\n",
    "\n",
    "# # Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "# print(idx_to_class)\n",
    "\n",
    "# # Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "# train_data_size = len(data['train'])\n",
    "# valid_data_size = len(data['valid'])\n",
    "# test_data_size = len(data['test'])\n",
    "\n",
    "# # Create iterators for the Data loaded using DataLoader module\n",
    "# train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "# valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)\n",
    "# test_data_loader = DataLoader(data['test'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9999, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size, valid_data_size, test_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet50 Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of ResNet50 Model for Transfer Learning\n",
    "fc_inputs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, num_classes), # Since 10 possible outputs\n",
    "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")\n",
    "\n",
    "# Convert model to be used on GPU\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "# loss_func = nn.NLLLoss()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25, save_location='./models'):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    print_every = 50\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs), flush=True)\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             print(labels)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            if (epoch * train_data_size + i) % print_every == 0:\n",
    "                print(\"Batch number: {:03d}/{:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, train_data_size // batch_size, loss.item(), acc.item()), flush=True)\n",
    "\n",
    "            if i == (train_data_size // batch_size // 3):\n",
    "                break\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        torch.save(model, save_location+'/model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "Batch number: 000/3125, Training: Loss: 4.6625, Accuracy: 0.0938\n",
      "Batch number: 050/3125, Training: Loss: 4.7143, Accuracy: 0.0312\n",
      "Batch number: 100/3125, Training: Loss: 4.9169, Accuracy: 0.0000\n",
      "Batch number: 150/3125, Training: Loss: 4.3047, Accuracy: 0.0938\n",
      "Batch number: 200/3125, Training: Loss: 4.5111, Accuracy: 0.0000\n",
      "Batch number: 250/3125, Training: Loss: 4.7360, Accuracy: 0.0625\n",
      "Batch number: 300/3125, Training: Loss: 4.4573, Accuracy: 0.0625\n",
      "Batch number: 350/3125, Training: Loss: 4.6760, Accuracy: 0.0625\n",
      "Batch number: 400/3125, Training: Loss: 4.7112, Accuracy: 0.0000\n",
      "Batch number: 450/3125, Training: Loss: 4.6527, Accuracy: 0.0625\n",
      "Batch number: 500/3125, Training: Loss: 4.7266, Accuracy: 0.0312\n",
      "Batch number: 550/3125, Training: Loss: 4.6994, Accuracy: 0.0625\n",
      "Batch number: 600/3125, Training: Loss: 4.6342, Accuracy: 0.0000\n",
      "Batch number: 650/3125, Training: Loss: 4.6800, Accuracy: 0.0625\n",
      "Batch number: 700/3125, Training: Loss: 4.7602, Accuracy: 0.0938\n",
      "Batch number: 750/3125, Training: Loss: 4.3329, Accuracy: 0.0625\n",
      "Batch number: 800/3125, Training: Loss: 4.6894, Accuracy: 0.0312\n",
      "Batch number: 850/3125, Training: Loss: 4.4346, Accuracy: 0.0625\n",
      "Batch number: 900/3125, Training: Loss: 4.4221, Accuracy: 0.1250\n",
      "Batch number: 950/3125, Training: Loss: 4.6024, Accuracy: 0.0938\n",
      "Batch number: 1000/3125, Training: Loss: 4.4040, Accuracy: 0.0938\n",
      "Epoch : 000, Training: Loss: 1.5529, Accuracy: 1.7940%, \n",
      "\t\tValidation : Loss : 6.1043, Accuracy: 0.6500%, Time: 190.5861s\n",
      "Epoch: 2/3\n",
      "Batch number: 000/3125, Training: Loss: 4.6117, Accuracy: 0.0312\n",
      "Batch number: 050/3125, Training: Loss: 4.6982, Accuracy: 0.0000\n",
      "Batch number: 100/3125, Training: Loss: 4.6394, Accuracy: 0.0000\n",
      "Batch number: 150/3125, Training: Loss: 4.6270, Accuracy: 0.0000\n",
      "Batch number: 200/3125, Training: Loss: 4.4844, Accuracy: 0.1562\n",
      "Batch number: 250/3125, Training: Loss: 4.5699, Accuracy: 0.0000\n",
      "Batch number: 300/3125, Training: Loss: 4.5168, Accuracy: 0.0625\n",
      "Batch number: 350/3125, Training: Loss: 4.1997, Accuracy: 0.0938\n",
      "Batch number: 400/3125, Training: Loss: 4.5832, Accuracy: 0.0312\n",
      "Batch number: 450/3125, Training: Loss: 4.7278, Accuracy: 0.0625\n",
      "Batch number: 500/3125, Training: Loss: 4.2692, Accuracy: 0.0625\n",
      "Batch number: 550/3125, Training: Loss: 4.3889, Accuracy: 0.0938\n",
      "Batch number: 600/3125, Training: Loss: 4.7761, Accuracy: 0.0000\n",
      "Batch number: 650/3125, Training: Loss: 4.5503, Accuracy: 0.0938\n",
      "Batch number: 700/3125, Training: Loss: 4.2745, Accuracy: 0.1875\n",
      "Batch number: 750/3125, Training: Loss: 4.8947, Accuracy: 0.0312\n",
      "Batch number: 800/3125, Training: Loss: 4.0599, Accuracy: 0.1250\n",
      "Batch number: 850/3125, Training: Loss: 4.2251, Accuracy: 0.1250\n",
      "Batch number: 900/3125, Training: Loss: 4.4666, Accuracy: 0.1250\n",
      "Batch number: 950/3125, Training: Loss: 4.7102, Accuracy: 0.0000\n",
      "Batch number: 1000/3125, Training: Loss: 4.2754, Accuracy: 0.1875\n",
      "Epoch : 001, Training: Loss: 1.5172, Accuracy: 2.2610%, \n",
      "\t\tValidation : Loss : 6.6015, Accuracy: 0.7400%, Time: 241.9512s\n",
      "Epoch: 3/3\n",
      "Batch number: 000/3125, Training: Loss: 4.4247, Accuracy: 0.0938\n",
      "Batch number: 050/3125, Training: Loss: 4.7113, Accuracy: 0.0000\n",
      "Batch number: 100/3125, Training: Loss: 4.7583, Accuracy: 0.0938\n",
      "Batch number: 150/3125, Training: Loss: 4.5981, Accuracy: 0.0625\n",
      "Batch number: 200/3125, Training: Loss: 4.6722, Accuracy: 0.0938\n",
      "Batch number: 250/3125, Training: Loss: 4.4136, Accuracy: 0.0625\n",
      "Batch number: 300/3125, Training: Loss: 4.5027, Accuracy: 0.1250\n",
      "Batch number: 350/3125, Training: Loss: 4.7013, Accuracy: 0.0625\n",
      "Batch number: 400/3125, Training: Loss: 4.5640, Accuracy: 0.0625\n",
      "Batch number: 450/3125, Training: Loss: 4.1193, Accuracy: 0.0625\n",
      "Batch number: 500/3125, Training: Loss: 4.5347, Accuracy: 0.0938\n",
      "Batch number: 550/3125, Training: Loss: 4.3866, Accuracy: 0.0938\n",
      "Batch number: 600/3125, Training: Loss: 4.3156, Accuracy: 0.0625\n",
      "Batch number: 650/3125, Training: Loss: 4.7635, Accuracy: 0.0625\n",
      "Batch number: 700/3125, Training: Loss: 4.3327, Accuracy: 0.0625\n",
      "Batch number: 750/3125, Training: Loss: 4.1716, Accuracy: 0.0938\n",
      "Batch number: 800/3125, Training: Loss: 4.7586, Accuracy: 0.1250\n",
      "Batch number: 850/3125, Training: Loss: 4.6506, Accuracy: 0.0312\n",
      "Batch number: 900/3125, Training: Loss: 4.7120, Accuracy: 0.0625\n",
      "Batch number: 950/3125, Training: Loss: 4.3743, Accuracy: 0.0938\n",
      "Batch number: 1000/3125, Training: Loss: 3.8721, Accuracy: 0.2188\n",
      "Epoch : 002, Training: Loss: 1.4894, Accuracy: 2.5540%, \n",
      "\t\tValidation : Loss : 6.6755, Accuracy: 0.8500%, Time: 260.9431s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a6ce93c0d206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_history.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print the model to be trained\n",
    "# summary(model, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')\n",
    "\n",
    "# Train the model for 25 epochs\n",
    "num_epochs = 10\n",
    "trained_model, history = train_and_validate(model, loss_func, optimizer, num_epochs)\n",
    "\n",
    "torch.save(history, 'image_net'+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(history, 'image_net'+'_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=200, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_only(model, loss_criterion, data_loader):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    print_every = 50\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # Set to training mode\n",
    "    model.eval()\n",
    "\n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "\n",
    "    # Validation - No gradient tracking needed\n",
    "    with torch.no_grad():\n",
    "        # Set to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Validation loop\n",
    "        for j, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # Compute total accuracy in the whole batch and add to valid_acc\n",
    "            valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Validation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        return avg_valid_acc, avg_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform_combo(transforms_combo):\n",
    "    data_transforms = transforms.Compose(transforms_combo)\n",
    "\n",
    "    # Load Data from folders\n",
    "    test_train_data = datasets.ImageFolder(root=data_dir / 'val', transform=data_transforms)\n",
    "\n",
    "    # Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "    test_train_data_size = len(test_train_data)\n",
    "\n",
    "    # Create iterators for the Data loaded using DataLoader module\n",
    "    test_train_data_loader = DataLoader(test_train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    avg_valid_acc, avg_valid_loss = validate_only(trained_model, loss_func, test_train_data_loader)\n",
    "    return avg_valid_acc, avg_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.6755, Accuracy: 0.8500%, Time: 15.0988s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"Default\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.6755, Accuracy: 0.8500%, Time: 15.0330s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"ColorJitter\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.3263, Accuracy: 0.7200%, Time: 15.9978s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.RandomAffine(180),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomAffine\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.7223, Accuracy: 0.8000%, Time: 15.2699s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomGrayScale0.1\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.9007, Accuracy: 0.5800%, Time: 15.6581s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.RandomGrayscale(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomGrayScale0.5\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.6737, Accuracy: 0.9300%, Time: 15.2010s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomHorizontalFlip0.5\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 7.2321, Accuracy: 0.5700%, Time: 18.8493s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomPerspective\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 6.6585, Accuracy: 0.8900%, Time: 15.0048s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomVerticalFlip0.5\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss : 7.0530, Accuracy: 0.7100%, Time: 15.5892s\n"
     ]
    }
   ],
   "source": [
    "transforms_combo = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0, 0, 0), tuple(np.sqrt((255, 255, 255)))),\n",
    "        transforms.RandomErasing()\n",
    "    ]\n",
    "\n",
    "avg_valid_acc, avg_valid_loss = test_transform_combo(transforms_combo)\n",
    "methods.append(\"RandomErasing0.5\")\n",
    "accuracies.append(avg_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Default',\n",
       " 'ColorJitter',\n",
       " 'RandomAffine',\n",
       " 'RandomGrayScale0.1',\n",
       " 'RandomGrayScale0.5',\n",
       " 'RandomHorizontalFlip0.5',\n",
       " 'RandomPerspective',\n",
       " 'RandomVerticalFlip0.5',\n",
       " 'RandomErasing0.5']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0085, 0.0085, 0.0072, 0.008, 0.0058, 0.0093, 0.0057, 0.0089, 0.0071]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '2f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-a1326f8f5aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mautolabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-a1326f8f5aa0>\u001b[0m in \u001b[0;36mautolabel\u001b[0;34m(rects)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         ax.annotate('{0.2f}'.format(height),\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mxytext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 3 points vertical offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '2f'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar_acc = ax.barh(methods, accuracies)\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Validation Accuracy After Transformations')\n",
    "ax.set_yticks(accuracies)\n",
    "ax.set_yticklabels(methods)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_width()\n",
    "        ax.annotate('{0.2f}'.format(height),\n",
    "                    xy=(rect.get_width(), rect.get_y() + rect.get_height()/2),\n",
    "                    xytext=(3, 0),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(bar_acc)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar_acc = ax.barh(methods, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Accuracy Vs. Adversarial Image Type')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar_acc = ax.barh([\"Default\", \"DeepFool\", \"Data Processing\", \"DeepFool + Data Processing\"], [0.4, 0.4*0.2, 0.4*0.75, 0.4*0.2*0.85])\n",
    "ax.set_xlabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Validation Accuracy Vs. Adversarial Image Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
